{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"pagetop\"></a>\n",
    "<div style=\"width:1000 px\">\n",
    "\n",
    "<div style=\"float:right; width:98 px; height:98px;\"><img src=\"https://pbs.twimg.com/profile_images/1187259618/unidata_logo_rgb_sm_400x400.png\" alt=\"Unidata Logo\" style=\"height: 98px;\"></div>\n",
    "\n",
    "<h1>Plotting Satellite Data</h1>\n",
    "<h3>Unidata Python Workshop</h3>\n",
    "\n",
    "<div style=\"clear:both\"></div>\n",
    "</div>\n",
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "<div style=\"float:right; width:250 px\"><img src=\"https://unidata.github.io/MetPy/latest/_images/sphx_glr_GINI_Water_Vapor_001.png\" alt=\"Example Satellite Image\" style=\"height: 500px;\"></div>\n",
    "\n",
    "### Questions\n",
    "1. Where are current GOES data available?\n",
    "1. How can satellite data be obtained with Siphon?\n",
    "1. How can MetPy simplify metadata parsing?\n",
    "1. How can maps of satellite data be made?\n",
    "\n",
    "### Table of Contents\n",
    "1. <a href=\"#findingdata\">Finding GOES data</a>\n",
    "1. <a href=\"#dataaccess\">Accessing data with Siphon</a>\n",
    "1. <a href=\"#parse\">Digging into and parsing the data</a>\n",
    "1. <a href=\"#plotting\">Plotting the data</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "<a name=\"findingdata\"></a>\n",
    "## Finding GOES Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to find the satellite data. Normally, we would browse over to http://thredds.ucar.edu/thredds/ and find the top-level [THREDDS Data Server (TDS)](https://www.unidata.ucar.edu/software/thredds/current/tds/TDS.html) catalog. From there we can drill down to find satellite data products.\n",
    "\n",
    "For current data, you could navigate to the `Satellite Data` directory, then `GOES East Products` and `CloudAndMoistureImagery`. There are subfolders for the CONUS, full disk, mesoscale sector images, and other products. In each of these is a folder for each [channel of the ABI](https://www.goes-r.gov/mission/ABI-bands-quick-info.html). In each channel there is a folder for every day in the approximately month-long rolling archive. As you can see, there are a massive amount of data coming down from GOES-16!\n",
    "\n",
    "In the next section we'll be downloading the data in a pythonic way, so our first task is to build a URL that matches the URL we manually navigated to in the web browser. To make it as flexible as possible, we'll want to use variables for the sector name (CONUS, full-disk, mesoscale-1, etc.), the date, and the ABI channel number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "         <li>Create variables named image_date, region, and channel. Assign them to today's date, the mesoscale-1 region, and ABI channel 8. </li>\n",
    "         <li>Construct a string data_url from these variables and the URL we navigated to above.</li>\n",
    "         <li>Verify that following your link will take you where you think it should.</li>\n",
    "         <li>Change the extension from catalog.html to catalog.xml. What do you see?</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Create variables for URL generation\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# Construct the data_url string\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# Print out your URL and verify it works!\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>SOLUTION</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/data_url.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#pagetop\">Top</a>\n",
    "<hr style=\"height:2px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"dataaccess\"></a>\n",
    "## Accessing data with Siphon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could download the files to our computers from the THREDDS web interface, but that can become tedious for downloading many files, requires us to store them on our computer, and does not lend itself to automation.\n",
    "\n",
    "We can use [Siphon](https://github.com/Unidata/siphon) to parse the catalog from the TDS. This provides us a nice programmatic way of accessing the data. We start by importing the `TDSCatalog` class from siphon and giving it the URL to the catalog we just surfed to manually. **Note:** Instead of giving it the link to the HTML catalog, we change the extension to XML, which asks the TDS for the XML version of the catalog. This is much better to work with in code. If you forget, the extension will be changed for you with a warning being issued from siphon.\n",
    "\n",
    "We want to create a `TDSCatalog` object called `cat` that we can examine and use to get handles to work with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from siphon.catalog import TDSCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = TDSCatalog(data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the latest file, we can look at the `cat.datasets` attribute. Let’s look at the first five datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.datasets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.datasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get the next to most recent dataset (sometimes the most recent will not have received all tiles yet) and store it as variable `dataset`. Note that we haven't actually downloaded or transferred any real data yet, just bits of metadata have been received from THREDDS and parsed by siphon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = cat.datasets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're finally ready to get the actual data. We could download the file, then open that, but there is no need! We can use siphon to help us only get what we need and hold it in memory. Notice that we're using the XArray accessor which will make life much nicer that dealing with the raw netCDF (like we used to back in the days of early 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.remote_access(use_xarray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#pagetop\">Top</a>\n",
    "<hr style=\"height:2px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"parse\"></a>\n",
    "## Digging into and parsing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got some data - let's see what we actually got our hands on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so we have an XArray Dataset object, something we've dealt with before! We also see that we have the coordinates `time`, `y`, and `x` as well as the data variables of `Sectorized_CMI` and the projection information. Using the MetPy accessor for xarray, we can pull out the data we need for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metpy\n",
    "dat = ds.metpy.parse_cf('Sectorized_CMI')\n",
    "proj = dat.metpy.cartopy_crs\n",
    "x = dat['x']\n",
    "y = dat['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#pagetop\">Top</a>\n",
    "<hr style=\"height:2px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"plotting\"></a>\n",
    "## Plotting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot our data we'll be using CartoPy and matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first make a simple plot using CartoPy's built-in shapefiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=proj)\n",
    "ax.add_feature(cfeature.COASTLINE.with_scale('50m'), linewidth=2)\n",
    "ax.add_feature(cfeature.STATES.with_scale('50m'), linestyle=':', edgecolor='black')\n",
    "ax.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=2, edgecolor='black')\n",
    "\n",
    "im = ax.imshow(dat, extent=(x.min(), x.max(), y.min(), y.max()), origin='upper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "         <li>Look at the documentation for metpy.plots.colortables <a href=\"https://unidata.github.io/MetPy/latest/api/generated/metpy.plots.ctables.ColortableRegistry.html#colortableregistry\">here</a> and figure out how to set the colormap of the image. For this image, let's go with the WVCIMSS_r colormap as this is a mid-level water vapor image. To see all of the colortables that MetPy supports, check out this <a href=\"https://unidata.github.io/MetPy/latest/api/generated/metpy.plots.ctables.html\">page</a></li>\n",
    "         <li>BONUS: Use the MetPy add_timestamp method from metpy.plots to add a timestamp to the plot.</li>\n",
    "         <li>DAILY DOUBLE: Using the start_date_time attribute on the dataset ds, change the call to add_timestamp to use that date and time and the pretext to say \"GOES 16 Channel X\".</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import for colortables\n",
    "from metpy.plots import colortables\n",
    "\n",
    "# Import for the bonus exercise\n",
    "from metpy.plots import add_timestamp\n",
    "\n",
    "# Make the image plot\n",
    "# YOUR CODE GOES HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>SOLUTION</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/sat_map.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More about Colortables\n",
    "Colormapping in matplotlib (which backs CartoPy) is handled through two pieces:\n",
    "\n",
    "- The norm (normalization) controls how data values are converted to floating point values in the range [0, 1]\n",
    "- The colormap controls how values are converted from floating point values in the range [0, 1] to colors (think colortable)\n",
    "\n",
    "Let's try to determine a good range of values for the normalization. We'll make a histogram to see the distribution of values in the data, then clip that range down to enhance contrast in the data visualization.\n",
    "\n",
    "We use `compressed` to remove any masked elements before making our histogram (areas of space that are in the view of the satellite)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(ds['Sectorized_CMI'].to_masked_array().compressed(), bins=255);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In meteorology, we have many ‘standard’ colortables that have been used for certain types of data. We have included these in Metpy in the `metpy.plots.ctables` module. The `WVCIMSS` colormap is a direct conversion of a GEMPAK colormap. Let's remake that image with a range of 195 to 265 K. This was empirically determined to closely match other displays of water vapor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=proj)\n",
    "ax.add_feature(cfeature.COASTLINE.with_scale('50m'), linewidth=2)\n",
    "ax.add_feature(cfeature.STATES.with_scale('50m'), linestyle=':', edgecolor='black')\n",
    "ax.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=2, edgecolor='black')\n",
    "\n",
    "im = ax.imshow(dat, extent=(x.min(), x.max(), y.min(), y.max()), origin='upper')\n",
    "\n",
    "wv_norm, wv_cmap = colortables.get_with_range('WVCIMSS_r', 195, 265)\n",
    "im.set_cmap(wv_cmap)\n",
    "im.set_norm(wv_norm)\n",
    "\n",
    "start_time = datetime.strptime(ds.start_date_time, '%Y%j%H%M%S')\n",
    "add_timestamp(ax, time=start_time, pretext=f'GOES-16 Ch. {channel} ',\n",
    "              high_contrast=True, fontsize=16, y=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#pagetop\">Top</a>\n",
    "<hr style=\"height:2px;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
